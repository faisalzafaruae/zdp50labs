---
  - name: Copy spark package to tmp directory
    copy:
        src: /home/zaloni/zdprpms/{{item}}
        dest: /tmp/zdp_install_temp_dir
    with_items:
        - "zdp-spark-5.0.0_FINAL.0-1.noarch.rpm"

#  - name: Install spark in server from local yum repository
#    yum:
#        name: "{{item}}"
#        enablerepo: "{{zdp_yum_repository_name}}"
#        skip_broken: yes
#    with_items:
#        - "zdp-spark"

  - name: Install mr in server from local RPM
    yum:
        name: "/tmp/zdp_install_temp_dir/{{item}}"
        state: present
    with_items:
        - "zdp-spark-5.0.0_FINAL.0-1.noarch.rpm"

## CONFIGURE THE YML

  - name: Configure zdp-spark.yml (STEP 1 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: fs.default.uri
        value: "{{ sparkexecutor_fs_default_uri }}"

  - name: Configure zdp-spark.yml (STEP 2 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: jdbc.spark.url
        value: "{{ sparkexecutor_jdbc_spark_url }}"

  - name: Configure zdp-spark.yml (STEP 3 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: jdbc.spark.username
        value: "{{ sparkexecutor_jdbc_spark_username }}"

  - name: Configure zdp-spark.yml (STEP 4 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: jdbc.spark.password
        value: "{{ sparkexecutor_jdbc_spark_password }}"

  - name: Configure zdp-spark.yml (STEP 5 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: jdbc.spark.driver
        value: "{{ sparkexecutor_jdbc_spark_driver }}"

  - name: Configure zdp-spark.yml (STEP 6 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: spark.master.url
        value: "{{ sparkexecutor_spark_master_url }}"

  - name: Configure zdp-spark.yml (STEP 7 of 7)
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: spark.version
        value: "{{ sparkexecutor_spark_master_version }}"

## CONFIGURE /etc/sysconfig/zdp-spark
  - name: Configure zdp-spark environment hadoop_conf_dir (STEP 1 of 3)
    become: True
    replace:
         path: /etc/sysconfig/zdp-spark
         regexp: '^hadoop_conf='
         replace: 'hadoop_conf={{ sparkexecutor_hadoop_conf }}'
         backup: no

  - name: Configure zdp-spark environment hadoop_conf_dir (STEP 2 of 3)
    become: True
    replace:
        path: /etc/sysconfig/zdp-spark
        regexp: '^spark_home='
        replace: 'spark_home={{ sparkexecutor_spark_home }}'
        backup: no

  - name: Configure zdp-spark environment hadoop_conf_dir (STEP 3 of 3)
    become: True
    replace:
        path: /etc/sysconfig/zdp-spark
        regexp: '^spark_lib='
        replace: 'spark_lib={{ sparkexecutor_spark_lib }}'
        backup: no

# Changes in case kerberos needs to be configured in zdp
  - name: Add keytab location to zdp-spark.yml
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: keytab.location
        value: "{{ zdp_keytab_location }}"
    when: zdp_kerberos_enable == True

  - name: Add keytab principal to zdp-spark.yml
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: keytab.principal
        value: "{{ zdp_kerberos_principal }}"
    when: zdp_kerberos_enable == True

  - name: Add krb5 conf location to zdp-spark.yml
    become: True
    yedit:
        src: /etc/zdp-spark/zdp-spark.yml
        key: kerberos.conf.location
        value: "{{ zdp_krb_conf_location }}"
    when: zdp_kerberos_enable == True

